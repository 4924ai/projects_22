{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tVc05w4N0n5"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow==1.15.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import zipfile\n",
        "from urllib import request\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2"
      ],
      "metadata": {
        "id": "3lSvsQVxN6iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_database = np.loadtxt('fashion-mnist_train.csv', delimiter=',', skiprows=1)[:,1:]\n",
        "#looking at the shape of the file\n",
        "print(img_database.shape)\n",
        "\n",
        "\n",
        "total_num_images = (img_database.shape[0])"
      ],
      "metadata": {
        "id": "Dd3f8D5BPivI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = 784 #Input image is of size 28 x 28\n",
        "hidden_layer_1 = 256\n",
        "hidden_layer_2 = 32\n",
        "hidden_layer_3 = 32\n",
        "hidden_layer_4 = 256\n",
        "output_layer = 784  #Same as the n_input dimension\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "# Define the placeholders\n",
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "Y = tf.placeholder(tf.float32, [None, output_layer])"
      ],
      "metadata": {
        "id": "LMQxjbo8PlZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Weight_NN = {\"W1\": tf.Variable(tf.random_normal([n_input, hidden_layer_1])),\n",
        "             \"W2\": tf.Variable(tf.random_normal([hidden_layer_1, hidden_layer_2])),\n",
        "             \"W3\": tf.Variable(tf.random_normal([hidden_layer_2, hidden_layer_3])),\n",
        "             \"W4\": tf.Variable(tf.random_normal([hidden_layer_3, hidden_layer_4])),\n",
        "             \"W5\": tf.Variable(tf.random_normal([hidden_layer_4, output_layer]))\n",
        "             }\n",
        "Bias_NN = { \"B1\": tf.Variable(tf.random_normal([hidden_layer_1])),\n",
        "            \"B2\": tf.Variable(tf.random_normal([hidden_layer_2])),\n",
        "            \"B3\": tf.Variable(tf.random_normal([hidden_layer_3])),\n",
        "            \"B4\": tf.Variable(tf.random_normal([hidden_layer_4])),\n",
        "            \"B5\": tf.Variable(tf.random_normal([output_layer]))\n",
        "           }"
      ],
      "metadata": {
        "id": "V71Y3KHVtoNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z1 = tf.add(tf.matmul(X, Weight_NN[\"W1\"]), Bias_NN[\"B1\"])\n",
        "Z1_out = tf.nn.sigmoid(Z1)\n",
        "\n",
        "Z2 = tf.add(tf.matmul(Z1_out, Weight_NN[\"W2\"]), Bias_NN[\"B2\"])\n",
        "Z2_out = tf.nn.sigmoid(Z2)\n",
        "\n",
        "Z3 = tf.add(tf.matmul(Z2_out, Weight_NN[\"W3\"]), Bias_NN[\"B2\"])\n",
        "Z3_out = tf.nn.sigmoid(Z3)\n",
        "\n",
        "Z4 = tf.add(tf.matmul(Z3_out, Weight_NN[\"W4\"]), Bias_NN[\"B4\"])\n",
        "Z4_out = tf.nn.sigmoid(Z4)\n",
        "\n",
        "Z5 = tf.add(tf.matmul(Z4_out, Weight_NN[\"W5\"]), Bias_NN[\"B5\"])\n",
        "Z5_out = tf.nn.sigmoid(Z5)"
      ],
      "metadata": {
        "id": "zDJkQPBdtsHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z1 = tf.layers.dense(X, hidden_layer_1, activation = tf.nn.sigmoid)\n",
        "Z2 = tf.layers.dense(Z1, hidden_layer_2, activation = tf.nn.sigmoid)\n",
        "Z3 = tf.layers.dense(Z1, hidden_layer_3, activation = tf.nn.sigmoid)\n",
        "Z4 = tf.layers.dense(Z1, hidden_layer_4, activation = tf.nn.sigmoid)\n",
        "NN_output = tf.layers.dense(Z4, output_layer)"
      ],
      "metadata": {
        "id": "Mux7eQR2tvvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(img_database)\n",
        "\n",
        "X_train = img_database\n",
        "\n",
        "# Normalize the dataset\n",
        "X_train = X_train\n",
        "\n",
        "# Create a noisy dataset\n",
        "X_train_noisy = X_train + 10* np.random.normal(0,1, size = X_train.shape)\n",
        "\n",
        "#Original image\n",
        "plt.imshow(X_train[0].reshape(28,28), cmap = 'gray')\n",
        "plt.show()\n",
        "\n",
        "#Noisy image\n",
        "plt.imshow(X_train_noisy[0].reshape(28,28), cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ggu5LwIft32R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the metrics\n",
        "\n",
        "# The loss function\n",
        "computed_loss = tf.reduce_mean(tf.square(NN_output-Y))\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(computed_loss)\n",
        "\n",
        "# Initialize the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "metadata": {
        "id": "euvMEqCYt91x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Session\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "for epoch in range(epochs):\n",
        "  for i in range(int(total_num_images/batch_size)):\n",
        "    X_epoch = X_train[ i*batch_size : (i+1)*batch_size ]\n",
        "    X_noise_epoch = X_train_noisy[ i*batch_size : (i+1)*batch_size ]\n",
        "    _, loss = sess.run([optimizer, computed_loss], feed_dict = {X: X_noise_epoch, Y: X_epoch})\n",
        "  print('Epoch', epoch, '/', epochs, 'loss:', loss)\n",
        "\n",
        "# pick any image\n",
        "X_actual = X_train[:10]\n",
        "noisy_image = X_train_noisy[:10]\n",
        "\n",
        "# run it though the autoencoder\n",
        "denoised_image = sess.run(NN_output, feed_dict={X:noisy_image})"
      ],
      "metadata": {
        "id": "nlorf-kOuAj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way of running session\n",
        "\n",
        "X_actual = X_train[20:30]\n",
        "noisy_image = X_train_noisy[20:30]\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  for epoch in range(epochs):\n",
        "    for i in range(int(total_num_images/batch_size)):\n",
        "      X_epoch = X_train[ i*batch_size : (i*1)*batch_size ]\n",
        "      X_noise_epoch = X_train_noisy[i*batch_size : (i*1)*batch_size ]\n",
        "      _, loss = sess.run([optimizer, computed_loss], feed_dict={X: X_noise_epoch, Y: X_epoch})\n",
        "    print('Epoch', epoch, '/', epochs, 'loss:', loss)\n",
        "  denoised_image = sess.run(NN_output, feed_dict = {X:noisy_image})\n",
        "\n",
        "#pick any image\n",
        "  \n",
        "\n",
        "# print the original image \n",
        "fig, axes = plt.subplots(nrows=3, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
        "for images, row in zip([X_actual, noisy_image, denoised_image], axes):\n",
        "    for img, ax in zip(images,row):\n",
        "        ax.imshow(img.reshape((28,28)), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "fig.tight_layout(pad=0.1)"
      ],
      "metadata": {
        "id": "u6_Ho-m4uFHB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}